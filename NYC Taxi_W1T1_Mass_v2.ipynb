{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Финальный проект. Анализ данных такси.\n",
    "## Неделя 1. Задание 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as sts\n",
    "import os\n",
    "import urllib.request\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "np.set_printoptions(precision=5, floatmode='maxprec', suppress=True)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оптимизация использования памяти\n",
    "Гайд: https://www.dataquest.io/blog/pandas-big-data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для конвертации в дату\n",
    "def to_date (data, cols, frm = '%Y-%m-%d %H:%M:%S'):\n",
    "    for i in cols:\n",
    "        data[i] = pd.to_datetime(data[i], format=frm)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Использование памяти (1000 строк): 0.09277725219726562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'float32'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/yellow_tripdata_2016-05.csv', nrows=1000)\n",
    "# Выбираем данные для преобразования типов\n",
    "data_float = data.select_dtypes(include=['float'])\n",
    "data_int = data.select_dtypes(include=['int'])\n",
    "# Преобразовываем типы\n",
    "converted_int = data_int.apply(pd.to_numeric,downcast='unsigned')\n",
    "converted_float = data_float.apply(pd.to_numeric,downcast='float')\n",
    "# Заменяем столбцы в исходных данных\n",
    "data[converted_int.columns] = converted_int\n",
    "data[converted_float.columns] = converted_float\n",
    "data.store_and_fwd_flag = data.store_and_fwd_flag.astype('category')\n",
    "data = to_date(data, ['tpep_pickup_datetime', 'tpep_dropoff_datetime'])\n",
    "\n",
    "print('Использование памяти ({} строк): {}'.format(len(data), data.memory_usage(deep = True).sum()/1024**2))\n",
    "# Создаем словарь стобцов данных и оптимальныз типов\n",
    "dtypes = data.drop(['tpep_pickup_datetime', 'tpep_dropoff_datetime'], axis = 1).dtypes\n",
    "dtypes_col = dtypes.index\n",
    "dtypes_type = [i.name for i in dtypes.values]\n",
    "column_types = dict(zip(dtypes_col, dtypes_type))\n",
    "column_types.update({'VendorID':'category', 'payment_type':'category'})\n",
    "column_types_2014 = column_types.copy()\n",
    "column_types_2014.pop('improvement_surcharge')\n",
    "#column_types_2014.update({np.nan:np.nan})\n",
    "#print(len(column_types), column_types)\n",
    "#print(len(column_types_2014), column_types_2014)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Необходимые фукции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_columns_list (all_dates, raw_data_urls):\n",
    "    #base_url = 'https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_'\n",
    "    #years = list(years)\n",
    "    #months = list(months)\n",
    "    #all_dates = [pd.to_datetime(str(y)+'.'+str(m)) for y in years for m in months]\n",
    "    # Проверяем, есть ли файл с заголовками и есть ли в нем строки по нуными месяцам\n",
    "    if not os.path.isfile('data_columns.csv'):\n",
    "        wrong = 1\n",
    "    else:\n",
    "        indices = pd.to_datetime(pd.read_csv('data_columns.csv', usecols=[0], index_col=0).index)\n",
    "        wrong = len([1 for date in all_dates if date not in indices])\n",
    "    # Cчитаем (или загружаем) файл с заголовками\n",
    "    if wrong > 0:\n",
    "        print('Start generating new columns dataset')\n",
    "        test = {str(y)+'.'+str(m):urllib.request.urlopen(url).readline().decode('utf-8').strip().split(',') \n",
    "                             for y,m,url,url_local in raw_data_urls}\n",
    "        for i in test.keys():\n",
    "            if   len(test[i]) != 19:    test[i].extend([np.nan]*(19-len(test[i])))\n",
    "        ## Создаем датафрейм ссо всеми колонками в данных (протестирована для 2014-2016 годов)        \n",
    "        data_columns = pd.DataFrame(test).transpose()\n",
    "        data_columns.index = pd.to_datetime(data_columns.index)\n",
    "        for i in data_columns:\n",
    "            data_columns[i] = data_columns[i].str.strip()\n",
    "        data_columns.to_csv('data_columns.csv')\n",
    "        print('Columns are saved at local file \"data_columns.csv\"')\n",
    "    else:\n",
    "        data_columns = pd.read_csv('data_columns.csv', index_col=0)\n",
    "        print('Columns are loaded from local file')\n",
    "    try:\n",
    "        up_to_2015_cols = list(data_columns.loc['2014-01-01'])[:-1]\n",
    "        up_to_2015_cols[:3], up_to_2015_cols[7],up_to_2015_cols[-5]  = ['VendorID','tpep_pickup_datetime','tpep_dropoff_datetime'], 'RateCodeID', 'extra'\n",
    "        return up_to_2015_cols\n",
    "    except:\n",
    "        print('Columns for dates before 2015 are not generated')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_LAT, MAX_LAT, MIN_LON, MAX_LON = 40.49612, 40.91553, -74.25559, -73.70001\n",
    "D_LAT = (MAX_LAT - MIN_LAT)/50.\n",
    "D_LON = (MAX_LON - MIN_LON)/50.\n",
    "def find_cell (df):\n",
    "    cells = (50*np.floor((df.pickup_longitude-MIN_LON)/D_LON) + np.floor((df.pickup_latitude-MIN_LAT)/D_LAT) +1).astype(int)\n",
    "    return cells\n",
    "\n",
    "# Функция для нахождения ячейки, в которой находится точка\n",
    "def find_point_cell(lon, lat):\n",
    "    try: return(int(50*np.floor((lon-MIN_LON)/D_LON) + np.floor((lat-MIN_LAT)/D_LAT))+1)\n",
    "    except IndexError: return ('Not in NYC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Функция для фильтрации датасета\n",
    "def filter_data(df):\n",
    "    df = df[(df.tpep_pickup_datetime != df.tpep_dropoff_datetime) &\n",
    "                (df.passenger_count  != 0) &\n",
    "                (df.trip_distance != 0) &\n",
    "                (df.pickup_longitude >= MIN_LON) & (df.pickup_longitude <= MAX_LON) &\n",
    "                (df.pickup_latitude >= MIN_LAT) & (df.pickup_latitude  <= MAX_LAT)]\n",
    "    df.reset_index(drop=True, inplace =True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, start_date, n_hours, verbose = None):\n",
    "    nrow_raw = len(df)\n",
    "    df = filter_data(df)\n",
    "    df.insert(column='hour',loc=len(df.columns),value=df.tpep_pickup_datetime.dt.floor('H'))\n",
    "    df.insert(column='trip_duration',loc=len(df.columns),value=(df.tpep_dropoff_datetime - df.tpep_pickup_datetime).dt.seconds)\n",
    "    df.insert(column='pickup_cell',loc=len(df.columns),value= pd.Series(find_cell(df),dtype='int16'))\n",
    "    test = pd.DataFrame({'hour_num':range(n_hours), 'hour':pd.DatetimeIndex(start = start_date, freq = 'H', periods = n_hours)})\n",
    "    df = df.merge(test, how='left', on = 'hour',)\n",
    "    if verbose == 'short' or verbose == 'full':\n",
    "        print('Было строк:{}. Осталось строк:{} ({:.2%})'.format(nrow_raw,len(df),(len(df) / nrow_raw)))\n",
    "    return (df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calulate_pivot(df, start_date, n_hours, verbose = None):\n",
    "    pivot = sts.binned_statistic_2d(x=df.pickup_cell, y=df.hour_num, values=None,statistic='count', \n",
    "                                range=[[1,2501], [0,n_hours]], bins=(2500, n_hours),\n",
    "                                expand_binnumbers = False)\n",
    "    ind = pd.DatetimeIndex(start = start_date, freq = 'H', periods = n_hours)\n",
    "    pivot = pd.DataFrame(pivot[0], index=range(1, 2501), columns=ind)\n",
    "    pivot = pivot.apply(pd.to_numeric, downcast = 'unsigned')\n",
    "    \n",
    "    # Проверка для тестирования\n",
    "    if verbose == 'full':\n",
    "        print('Размерность сводной таблицы:',pivot.shape)\n",
    "        print('Сумма элементов сводной таблицы:', pivot.sum().sum())\n",
    "        print('Кол-во строк в исходных данных:', len(df))\n",
    "    return pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_urls(urls, verbose = 'short', nrows = None, return_data = False, return_pivot = False, save_to_disk = False):\n",
    "    '''функция обрабатывает данные по списку ссылокБ созданных заранее. Она проверяет наличие файла на жестком диске,\n",
    "    а затем фильтрует данные, рассчитывает новые столбцы и сводные таблицы (для работы необходимы функции filter_data, \n",
    "    preprocess_data и calculate_pivot).\n",
    "    Затем обработанные файлы сохраняются обратно, а сводные таблицы сохраняются в отдельную папку\n",
    "    Параметр verbose: принимает значения 'full', 'short', 'basic' - для полного вывода всех тестовых данных \n",
    "    подфункций, вывода промежуточных статусов обработки и вывода только основных этапов обработки для мониторинга процесса\n",
    "    '''\n",
    "    down_files = list(os.listdir('data')) # директория с данными (hardcoded)\n",
    "    #up_to_2015_cols = load_columns_list\n",
    "    for y, m, url, url_local in urls:        \n",
    "        if url_local not in down_files: # переходим к следующему файлу, если текущий не загружен на жесткий диск\n",
    "            print('!!! Data for {} is not downloaded\\n'.format(str(m)+'.'+str(y)))\n",
    "        elif y == 2016 and m>6:\n",
    "            print('Data for {} has different structure and will not be analyzed'.format(str(m)+'.'+str(y)))\n",
    "        else:\n",
    "            n = datetime.now()\n",
    "            print(n.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "            print(y, m)\n",
    "            print('Start processing data for :', str(m)+'.'+str(y))\n",
    "            start_date = pd.Timestamp(y, m, 1)\n",
    "            n_hours = start_date.daysinmonth * 24\n",
    "            if y < 2015:\n",
    "                test = pd.read_csv('data/'+url_local, dtype=column_types_2014, names = up_to_2015_cols, nrows=nrows,\n",
    "                                    header = 0, parse_dates=['tpep_pickup_datetime', 'tpep_dropoff_datetime'], \n",
    "                                    infer_datetime_format=True)  # для теста загружаются первые 10 строк\n",
    "                #test.columns = up_to_2015_cols\n",
    "                test.insert(18, 'improvement_surcharge', 0)\n",
    "            else: \n",
    "                test = pd.read_csv('data/'+url_local, dtype=column_types, nrows=nrows,\n",
    "                                    parse_dates=['tpep_pickup_datetime', 'tpep_dropoff_datetime'],\n",
    "                                    infer_datetime_format=True,)  # для теста загружаются первые 10 строк\n",
    "            if verbose == 'full': \n",
    "                print('Data was successfully read')\n",
    "                print('Starting preprocessing data')\n",
    "            # Расчет новых столбцов и сохранение данных\n",
    "            test = preprocess_data(test, start_date, n_hours, verbose)\n",
    "            \n",
    "            \n",
    "            # Расчет и сохранение сводных таблиц\n",
    "            if verbose == 'full':\n",
    "                print('Starting calculate pivot')\n",
    "            pivot = calulate_pivot(test, start_date, n_hours, verbose)\n",
    "            \n",
    "            if save_to_disk:\n",
    "                #test.to_csv('data/test/test_'+url_local,index=None)\n",
    "                pivot.to_csv('data/pivots/pivot_'+url_local)\n",
    "            \n",
    "            print('Data was successfully processed')\n",
    "            print('Время обработки файла:', str(datetime.now()- n),'\\n')\n",
    "            \n",
    "            if return_data and len(urls) == 1 and return_pivot == False:\n",
    "                return test\n",
    "            if return_data == False and len(urls) == 1 and return_pivot:\n",
    "                return pivot\n",
    "            if return_data and len(urls)==1 and return_pivot:\n",
    "                return test, pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка для массового импорта данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Импорт данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns are loaded from local file\n"
     ]
    }
   ],
   "source": [
    "# Выбираем нужный период и генерируем список ссылок на файлы\n",
    "regions = pd.read_csv('regions.csv', sep = ';')\n",
    "min_date = '2014.06'\n",
    "max_date = '2016.06'\n",
    "\n",
    "raw_urls, periods = generate_urls(min_date, max_date)\n",
    "up_to_2015_cols = load_columns_list(periods, raw_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2014,\n",
       "  6,\n",
       "  'https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2014-06.csv',\n",
       "  'yellow_tripdata_2014-06.csv'),\n",
       " (2014,\n",
       "  7,\n",
       "  'https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2014-07.csv',\n",
       "  'yellow_tripdata_2014-07.csv'),\n",
       " (2014,\n",
       "  8,\n",
       "  'https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2014-08.csv',\n",
       "  'yellow_tripdata_2014-08.csv'),\n",
       " (2014,\n",
       "  9,\n",
       "  'https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2014-09.csv',\n",
       "  'yellow_tripdata_2014-09.csv'),\n",
       " (2014,\n",
       "  10,\n",
       "  'https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2014-10.csv',\n",
       "  'yellow_tripdata_2014-10.csv'),\n",
       " (2014,\n",
       "  11,\n",
       "  'https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2014-11.csv',\n",
       "  'yellow_tripdata_2014-11.csv'),\n",
       " (2014,\n",
       "  12,\n",
       "  'https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2014-12.csv',\n",
       "  'yellow_tripdata_2014-12.csv'),\n",
       " (2015,\n",
       "  1,\n",
       "  'https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2015-01.csv',\n",
       "  'yellow_tripdata_2015-01.csv'),\n",
       " (2015,\n",
       "  2,\n",
       "  'https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2015-02.csv',\n",
       "  'yellow_tripdata_2015-02.csv'),\n",
       " (2015,\n",
       "  3,\n",
       "  'https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2015-03.csv',\n",
       "  'yellow_tripdata_2015-03.csv'),\n",
       " (2015,\n",
       "  4,\n",
       "  'https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2015-04.csv',\n",
       "  'yellow_tripdata_2015-04.csv'),\n",
       " (2015,\n",
       "  5,\n",
       "  'https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2015-05.csv',\n",
       "  'yellow_tripdata_2015-05.csv'),\n",
       " (2015,\n",
       "  6,\n",
       "  'https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2015-06.csv',\n",
       "  'yellow_tripdata_2015-06.csv'),\n",
       " (2015,\n",
       "  7,\n",
       "  'https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2015-07.csv',\n",
       "  'yellow_tripdata_2015-07.csv'),\n",
       " (2015,\n",
       "  8,\n",
       "  'https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2015-08.csv',\n",
       "  'yellow_tripdata_2015-08.csv'),\n",
       " (2015,\n",
       "  9,\n",
       "  'https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2015-09.csv',\n",
       "  'yellow_tripdata_2015-09.csv'),\n",
       " (2015,\n",
       "  10,\n",
       "  'https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2015-10.csv',\n",
       "  'yellow_tripdata_2015-10.csv'),\n",
       " (2015,\n",
       "  11,\n",
       "  'https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2015-11.csv',\n",
       "  'yellow_tripdata_2015-11.csv'),\n",
       " (2015,\n",
       "  12,\n",
       "  'https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2015-12.csv',\n",
       "  'yellow_tripdata_2015-12.csv'),\n",
       " (2016,\n",
       "  1,\n",
       "  'https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2016-01.csv',\n",
       "  'yellow_tripdata_2016-01.csv'),\n",
       " (2016,\n",
       "  2,\n",
       "  'https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2016-02.csv',\n",
       "  'yellow_tripdata_2016-02.csv'),\n",
       " (2016,\n",
       "  3,\n",
       "  'https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2016-03.csv',\n",
       "  'yellow_tripdata_2016-03.csv'),\n",
       " (2016,\n",
       "  4,\n",
       "  'https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2016-04.csv',\n",
       "  'yellow_tripdata_2016-04.csv'),\n",
       " (2016,\n",
       "  5,\n",
       "  'https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2016-05.csv',\n",
       "  'yellow_tripdata_2016-05.csv'),\n",
       " (2016,\n",
       "  6,\n",
       "  'https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2016-06.csv',\n",
       "  'yellow_tripdata_2016-06.csv')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_urls\n",
    "#column_types_2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-07-04 17:52:26\n",
      "2014 6\n",
      "Start processing data for : 6.2014\n",
      "Data was successfully read\n",
      "Starting preprocessing data\n",
      "Было строк:13813029. Осталось строк:13374918 (96.83%)\n",
      "Starting calculate pivot\n",
      "Размерность сводной таблицы: (2500, 720)\n",
      "Сумма элементов сводной таблицы: 13374918\n",
      "Кол-во строк в исходных данных: 13374918\n",
      "Data was successfully processed\n",
      "Время обработки файла: 0:02:26.610997 \n",
      "\n",
      "2018-07-04 17:54:52\n",
      "2014 7\n",
      "Start processing data for : 7.2014\n",
      "Data was successfully read\n",
      "Starting preprocessing data\n",
      "Было строк:13106365. Осталось строк:12683644 (96.77%)\n",
      "Starting calculate pivot\n",
      "Размерность сводной таблицы: (2500, 744)\n",
      "Сумма элементов сводной таблицы: 12683644\n",
      "Кол-во строк в исходных данных: 12683644\n",
      "Data was successfully processed\n",
      "Время обработки файла: 0:02:15.319773 \n",
      "\n",
      "2018-07-04 17:57:08\n",
      "2014 8\n",
      "Start processing data for : 8.2014\n",
      "Data was successfully read\n",
      "Starting preprocessing data\n",
      "Было строк:12688877. Осталось строк:12280367 (96.78%)\n",
      "Starting calculate pivot\n",
      "Размерность сводной таблицы: (2500, 744)\n",
      "Сумма элементов сводной таблицы: 12280367\n",
      "Кол-во строк в исходных данных: 12280367\n",
      "Data was successfully processed\n",
      "Время обработки файла: 0:01:44.742481 \n",
      "\n",
      "2018-07-04 17:58:52\n",
      "2014 9\n",
      "Start processing data for : 9.2014\n",
      "Data was successfully read\n",
      "Starting preprocessing data\n",
      "Было строк:13374016. Осталось строк:13036158 (97.47%)\n",
      "Starting calculate pivot\n",
      "Размерность сводной таблицы: (2500, 720)\n",
      "Сумма элементов сводной таблицы: 13036158\n",
      "Кол-во строк в исходных данных: 13036158\n",
      "Data was successfully processed\n",
      "Время обработки файла: 0:02:41.608020 \n",
      "\n",
      "2018-07-04 18:01:34\n",
      "2014 10\n",
      "Start processing data for : 10.2014\n",
      "Data was successfully read\n",
      "Starting preprocessing data\n",
      "Было строк:14232487. Осталось строк:13927665 (97.86%)\n",
      "Starting calculate pivot\n",
      "Размерность сводной таблицы: (2500, 744)\n",
      "Сумма элементов сводной таблицы: 13927665\n",
      "Кол-во строк в исходных данных: 13927665\n",
      "Data was successfully processed\n",
      "Время обработки файла: 0:02:39.084461 \n",
      "\n",
      "2018-07-04 18:04:13\n",
      "2014 11\n",
      "Start processing data for : 11.2014\n",
      "Data was successfully read\n",
      "Starting preprocessing data\n",
      "Было строк:13218216. Осталось строк:12912183 (97.68%)\n",
      "Starting calculate pivot\n",
      "Размерность сводной таблицы: (2500, 720)\n",
      "Сумма элементов сводной таблицы: 12912183\n",
      "Кол-во строк в исходных данных: 12912183\n",
      "Data was successfully processed\n",
      "Время обработки файла: 0:02:15.653983 \n",
      "\n",
      "2018-07-04 18:06:29\n",
      "2014 12\n",
      "Start processing data for : 12.2014\n",
      "Data was successfully read\n",
      "Starting preprocessing data\n",
      "Было строк:13014161. Осталось строк:12706750 (97.64%)\n",
      "Starting calculate pivot\n",
      "Размерность сводной таблицы: (2500, 744)\n",
      "Сумма элементов сводной таблицы: 12706750\n",
      "Кол-во строк в исходных данных: 12706750\n",
      "Data was successfully processed\n",
      "Время обработки файла: 0:01:49.551532 \n",
      "\n",
      "2018-07-04 18:08:18\n",
      "2015 1\n",
      "Start processing data for : 1.2015\n",
      "Data was successfully read\n",
      "Starting preprocessing data\n",
      "Было строк:12748986. Осталось строк:12434194 (97.53%)\n",
      "Starting calculate pivot\n",
      "Размерность сводной таблицы: (2500, 744)\n",
      "Сумма элементов сводной таблицы: 12434194\n",
      "Кол-во строк в исходных данных: 12434194\n",
      "Data was successfully processed\n",
      "Время обработки файла: 0:01:43.288357 \n",
      "\n",
      "2018-07-04 18:10:02\n",
      "2015 2\n",
      "Start processing data for : 2.2015\n",
      "Data was successfully read\n",
      "Starting preprocessing data\n",
      "Было строк:12450521. Осталось строк:12134859 (97.46%)\n",
      "Starting calculate pivot\n",
      "Размерность сводной таблицы: (2500, 672)\n",
      "Сумма элементов сводной таблицы: 12134859\n",
      "Кол-во строк в исходных данных: 12134859\n",
      "Data was successfully processed\n",
      "Время обработки файла: 0:01:45.691854 \n",
      "\n",
      "2018-07-04 18:11:47\n",
      "2015 3\n",
      "Start processing data for : 3.2015\n",
      "Data was successfully read\n",
      "Starting preprocessing data\n",
      "Было строк:13351609. Осталось строк:13022265 (97.53%)\n",
      "Starting calculate pivot\n",
      "Размерность сводной таблицы: (2500, 744)\n",
      "Сумма элементов сводной таблицы: 13022265\n",
      "Кол-во строк в исходных данных: 13022265\n",
      "Data was successfully processed\n",
      "Время обработки файла: 0:01:41.667271 \n",
      "\n",
      "2018-07-04 18:13:29\n",
      "2015 4\n",
      "Start processing data for : 4.2015\n",
      "Data was successfully read\n",
      "Starting preprocessing data\n",
      "Было строк:13071789. Осталось строк:12777176 (97.75%)\n",
      "Starting calculate pivot\n",
      "Размерность сводной таблицы: (2500, 720)\n",
      "Сумма элементов сводной таблицы: 12777176\n",
      "Кол-во строк в исходных данных: 12777176\n",
      "Data was successfully processed\n",
      "Время обработки файла: 0:01:46.887280 \n",
      "\n",
      "2018-07-04 18:15:16\n",
      "2015 5\n",
      "Start processing data for : 5.2015\n",
      "Data was successfully read\n",
      "Starting preprocessing data\n",
      "Было строк:13158262. Осталось строк:12886906 (97.94%)\n",
      "Starting calculate pivot\n",
      "Размерность сводной таблицы: (2500, 744)\n",
      "Сумма элементов сводной таблицы: 12886906\n",
      "Кол-во строк в исходных данных: 12886906\n",
      "Data was successfully processed\n",
      "Время обработки файла: 0:01:52.772032 \n",
      "\n",
      "2018-07-04 18:17:09\n",
      "2015 6\n",
      "Start processing data for : 6.2015\n",
      "Data was successfully read\n",
      "Starting preprocessing data\n",
      "Было строк:12324935. Осталось строк:12081675 (98.03%)\n",
      "Starting calculate pivot\n",
      "Размерность сводной таблицы: (2500, 720)\n",
      "Сумма элементов сводной таблицы: 12081675\n",
      "Кол-во строк в исходных данных: 12081675\n",
      "Data was successfully processed\n",
      "Время обработки файла: 0:01:55.311697 \n",
      "\n",
      "2018-07-04 18:19:04\n",
      "2015 7\n",
      "Start processing data for : 7.2015\n",
      "Data was successfully read\n",
      "Starting preprocessing data\n",
      "Было строк:11562783. Осталось строк:11340888 (98.08%)\n",
      "Starting calculate pivot\n",
      "Размерность сводной таблицы: (2500, 744)\n",
      "Сумма элементов сводной таблицы: 11340888\n",
      "Кол-во строк в исходных данных: 11340888\n",
      "Data was successfully processed\n",
      "Время обработки файла: 0:01:34.054072 \n",
      "\n",
      "2018-07-04 18:20:38\n",
      "2015 8\n",
      "Start processing data for : 8.2015\n",
      "Data was successfully read\n",
      "Starting preprocessing data\n",
      "Было строк:11130304. Осталось строк:10915801 (98.07%)\n",
      "Starting calculate pivot\n",
      "Размерность сводной таблицы: (2500, 744)\n",
      "Сумма элементов сводной таблицы: 10915801\n",
      "Кол-во строк в исходных данных: 10915801\n",
      "Data was successfully processed\n",
      "Время обработки файла: 0:01:27.928778 \n",
      "\n",
      "2018-07-04 18:22:06\n",
      "2015 9\n",
      "Start processing data for : 9.2015\n",
      "Data was successfully read\n",
      "Starting preprocessing data\n",
      "Было строк:11225063. Осталось строк:11010025 (98.08%)\n",
      "Starting calculate pivot\n",
      "Размерность сводной таблицы: (2500, 720)\n",
      "Сумма элементов сводной таблицы: 11010025\n",
      "Кол-во строк в исходных данных: 11010025\n",
      "Data was successfully processed\n",
      "Время обработки файла: 0:01:43.755782 \n",
      "\n",
      "2018-07-04 18:23:50\n",
      "2015 10\n",
      "Start processing data for : 10.2015\n",
      "Data was successfully read\n",
      "Starting preprocessing data\n",
      "Было строк:12315488. Осталось строк:12072756 (98.03%)\n",
      "Starting calculate pivot\n",
      "Размерность сводной таблицы: (2500, 744)\n",
      "Сумма элементов сводной таблицы: 12072756\n",
      "Кол-во строк в исходных данных: 12072756\n",
      "Data was successfully processed\n",
      "Время обработки файла: 0:01:34.573194 \n",
      "\n",
      "2018-07-04 18:25:24\n",
      "2015 11\n",
      "Start processing data for : 11.2015\n",
      "Data was successfully read\n",
      "Starting preprocessing data\n",
      "Было строк:11312676. Осталось строк:11080466 (97.95%)\n",
      "Starting calculate pivot\n",
      "Размерность сводной таблицы: (2500, 720)\n",
      "Сумма элементов сводной таблицы: 11080466\n",
      "Кол-во строк в исходных данных: 11080466\n",
      "Data was successfully processed\n",
      "Время обработки файла: 0:01:39.494900 \n",
      "\n",
      "2018-07-04 18:27:04\n",
      "2015 12\n",
      "Start processing data for : 12.2015\n",
      "Data was successfully read\n",
      "Starting preprocessing data\n",
      "Было строк:11460573. Осталось строк:11229374 (97.98%)\n",
      "Starting calculate pivot\n",
      "Размерность сводной таблицы: (2500, 744)\n",
      "Сумма элементов сводной таблицы: 11229374\n",
      "Кол-во строк в исходных данных: 11229374\n",
      "Data was successfully processed\n",
      "Время обработки файла: 0:01:38.431897 \n",
      "\n",
      "2018-07-04 18:28:42\n",
      "2016 1\n",
      "Start processing data for : 1.2016\n",
      "Data was successfully read\n",
      "Starting preprocessing data\n",
      "Было строк:10906858. Осталось строк:10682273 (97.94%)\n",
      "Starting calculate pivot\n",
      "Размерность сводной таблицы: (2500, 744)\n",
      "Сумма элементов сводной таблицы: 10682273\n",
      "Кол-во строк в исходных данных: 10682273\n",
      "Data was successfully processed\n",
      "Время обработки файла: 0:01:46.451978 \n",
      "\n",
      "2018-07-04 18:30:29\n",
      "2016 2\n",
      "Start processing data for : 2.2016\n",
      "Data was successfully read\n",
      "Starting preprocessing data\n",
      "Было строк:11382049. Осталось строк:11147482 (97.94%)\n",
      "Starting calculate pivot\n",
      "Размерность сводной таблицы: (2500, 696)\n",
      "Сумма элементов сводной таблицы: 11147482\n",
      "Кол-во строк в исходных данных: 11147482\n",
      "Data was successfully processed\n",
      "Время обработки файла: 0:01:58.271511 \n",
      "\n",
      "2018-07-04 18:32:27\n",
      "2016 3\n",
      "Start processing data for : 3.2016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data was successfully read\n",
      "Starting preprocessing data\n",
      "Было строк:12210952. Осталось строк:11968419 (98.01%)\n",
      "Starting calculate pivot\n",
      "Размерность сводной таблицы: (2500, 744)\n",
      "Сумма элементов сводной таблицы: 11968419\n",
      "Кол-во строк в исходных данных: 11968419\n",
      "Data was successfully processed\n",
      "Время обработки файла: 0:01:26.342155 \n",
      "\n",
      "2018-07-04 18:33:53\n",
      "2016 4\n",
      "Start processing data for : 4.2016\n",
      "Data was successfully read\n",
      "Starting preprocessing data\n",
      "Было строк:11934338. Осталось строк:11697034 (98.01%)\n",
      "Starting calculate pivot\n",
      "Размерность сводной таблицы: (2500, 720)\n",
      "Сумма элементов сводной таблицы: 11697034\n",
      "Кол-во строк в исходных данных: 11697034\n",
      "Data was successfully processed\n",
      "Время обработки файла: 0:01:29.908234 \n",
      "\n",
      "2018-07-04 18:35:23\n",
      "2016 5\n",
      "Start processing data for : 5.2016\n",
      "Data was successfully read\n",
      "Starting preprocessing data\n",
      "Было строк:11836853. Осталось строк:11626521 (98.22%)\n",
      "Starting calculate pivot\n",
      "Размерность сводной таблицы: (2500, 744)\n",
      "Сумма элементов сводной таблицы: 11626521\n",
      "Кол-во строк в исходных данных: 11626521\n",
      "Data was successfully processed\n",
      "Время обработки файла: 0:01:30.064093 \n",
      "\n",
      "2018-07-04 18:36:53\n",
      "2016 6\n",
      "Start processing data for : 6.2016\n",
      "Data was successfully read\n",
      "Starting preprocessing data\n",
      "Было строк:11135470. Осталось строк:10936046 (98.21%)\n",
      "Starting calculate pivot\n",
      "Размерность сводной таблицы: (2500, 720)\n",
      "Сумма элементов сводной таблицы: 10936046\n",
      "Кол-во строк в исходных данных: 10936046\n",
      "Data was successfully processed\n",
      "Время обработки файла: 0:01:23.230966 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "process_urls(urls=raw_urls, return_data=True, return_pivot=False, verbose='full', save_to_disk=True)#, nrows=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### График количества поездок от ESB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell for Empire State Building: 1231\n"
     ]
    }
   ],
   "source": [
    "# Empire State Building coordinates\n",
    "esb_lat = 40.748412\n",
    "esb_long = -73.985860\n",
    "esb_cell = find_point_cell(esb_long, esb_lat)\n",
    "print('Cell for Empire State Building:',esb_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pivot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-90548369298b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpivot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pivot' is not defined"
     ]
    }
   ],
   "source": [
    "pivot.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.grid()\n",
    "plt.plot(range(744), pivot.loc[esb_cell,:])#, width = 1, align = 'edge', tick_label = range(24))\n",
    "\n",
    "plt.title('Trips from ESB by hours')\n",
    "plt.xlabel('$Hour$')\n",
    "plt.ylabel('Trip   count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подсчет количества пар ячейка-час, из которых не было поездок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pivot==0).sum().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
